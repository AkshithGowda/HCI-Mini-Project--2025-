{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e4a737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.utils import resample\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "import joblib\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b79ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0570ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_full_model():\n",
    "    print(\"--- Starting Keras 5-CLASS Model Building Process ---\")\n",
    "\n",
    "    # --- Step 1: Load and Prepare Data (Scikit-learn) ---\n",
    "    print(\"Step 1: Loading and Preparing Data...\")\n",
    "    try:\n",
    "        # Using the filename you specified\n",
    "        df = pd.read_csv('Combined_Real_Movements.csv')\n",
    "        df = df.dropna() # Drop any rows with missing data\n",
    "\n",
    "        # --- Data Balancing for 5 Classes ---\n",
    "        # Find the size of the smallest class\n",
    "        class_counts = df['Classes'].value_counts()\n",
    "        min_class_size = class_counts.min()\n",
    "        print(f\"Original class counts:\\n{class_counts}\")\n",
    "        print(f\"Smallest class has {min_class_size} samples. Balancing all classes to this size.\")\n",
    "\n",
    "        # Create a new balanced dataframe\n",
    "        df_balanced = pd.DataFrame()\n",
    "        for class_name in class_counts.index:\n",
    "            df_class = df[df['Classes'] == class_name]\n",
    "            df_class_downsampled = resample(df_class, \n",
    "                                             replace=False, # sample without replacement\n",
    "                                             n_samples=min_class_size, # to match smallest class\n",
    "                                             random_state=42)\n",
    "            df_balanced = pd.concat([df_balanced, df_class_downsampled])\n",
    "\n",
    "        print(f\"Data balanced. Total samples: {len(df_balanced)}.\")\n",
    "        print(f\"New class counts:\\n{df_balanced['Classes'].value_counts()}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: 'Combined_Real_Movements.csv' not found.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during data loading: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- Step 2: Define Features (X) and Target (y) ---\n",
    "    print(\"\\nStep 2: Defining Features (X) and Target (y)...\")\n",
    "    features = [col for col in df_balanced.columns if col not in ['Classes', 'Subject']]\n",
    "    target = 'Classes'\n",
    "\n",
    "    X = df_balanced[features]\n",
    "    y = df_balanced[target]\n",
    "\n",
    "    # --- Step 3: Preprocessing (Scikit-learn) ---\n",
    "    print(\"Step 3: Preprocessing Data...\")\n",
    "    \n",
    "    # 3a: Encode Target Variable (y) for Keras\n",
    "    # Keras needs numerical labels (0, 1, 2, 3, 4) instead of text\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    # Save the label encoder so we can decode predictions later\n",
    "    joblib.dump(le, 'label_encoder.joblib')\n",
    "    print(f\"Target classes encoded: {le.classes_} -> {np.unique(y_encoded)}\")\n",
    "\n",
    "    # 3b: Define Preprocessing for Features (X)\n",
    "    numeric_features = X.select_dtypes(include='number').columns.tolist()\n",
    "    \n",
    "    # Check if 'WaveType' exists.\n",
    "    if 'WaveType' in X.columns:\n",
    "        print(\"Found 'WaveType' column. Will use it as a categorical feature.\")\n",
    "        categorical_features = ['WaveType']\n",
    "        # We use sparse_output=False to ensure Keras receives a dense array\n",
    "        preprocessor = make_column_transformer(\n",
    "            (StandardScaler(), numeric_features),\n",
    "            (OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features)\n",
    "        )\n",
    "    else:\n",
    "        print(\"Warning: 'WaveType' column not found. Proceeding with numeric features only.\")\n",
    "        categorical_features = []\n",
    "        preprocessor = make_column_transformer(\n",
    "            (StandardScaler(), numeric_features)\n",
    "        )\n",
    "\n",
    "    # 3c: Split and Preprocess Data\n",
    "    # Stratify ensures we keep the class balance in both train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.25, random_state=42, stratify=y_encoded)\n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "    \n",
    "    # Save the preprocessor\n",
    "    joblib.dump(preprocessor, 'data_preprocessor.joblib')\n",
    "    print(\"Data preprocessor (scaler/encoder) saved.\")\n",
    "\n",
    "    print(f\"Training features shape: {X_train_processed.shape}\")\n",
    "    print(f\"Testing features shape: {X_test_processed.shape}\")\n",
    "\n",
    "    # --- Step 4: Build Keras Model ---\n",
    "    print(\"\\nStep 4: Building Keras Neural Network...\")\n",
    "    \n",
    "    n_features = X_train_processed.shape[1]\n",
    "    n_classes = len(le.classes_) # Should be 5\n",
    "\n",
    "    model = Sequential()\n",
    "    # Explicit Input layer is cleaner in newer Keras versions\n",
    "    model.add(Input(shape=(n_features,)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3)) \n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Output layer: n_classes (5) neurons and 'softmax' activation\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model: 'sparse_categorical_crossentropy' for multi-class\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # --- Step 5: Train Keras Model ---\n",
    "    print(\"\\nStep 5: Training Keras Model...\")\n",
    "    history = model.fit(\n",
    "        X_train_processed,\n",
    "        y_train,\n",
    "        validation_data=(X_test_processed, y_test),\n",
    "        epochs=30, \n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # --- Step 6: Evaluate Keras Model (Scikit-learn) ---\n",
    "    print(\"\\nStep 6: Evaluating Keras Model...\")\n",
    "    \n",
    "    # Get probability predictions from Keras\n",
    "    y_pred_proba = model.predict(X_test_processed)\n",
    "    \n",
    "    # Convert probabilities to class labels using argmax\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "    # Use Scikit-learn's tools for a clear report\n",
    "    y_test_labels = le.inverse_transform(y_test)\n",
    "    y_pred_labels = le.inverse_transform(y_pred)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "    print(f\"\\nModel Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_labels, y_pred_labels))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "    cm_df = pd.DataFrame(cm, \n",
    "                       index=[f'Actual: {c}' for c in le.classes_], \n",
    "                       columns=[f'Pred: {c}' for c in le.classes_])\n",
    "    print(cm_df)\n",
    "\n",
    "    # --- Step 7: Save the Trained Model ---\n",
    "    print(\"\\nStep 7: Saving Trained Model...\")\n",
    "    model.save('keras_bci_model_5_class.h5')\n",
    "    print(\"Keras model saved to 'keras_bci_model_5_class.h5'\")\n",
    "    print(\"--- Model Building Process Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d990db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the entire process\n",
    "if __name__ == \"__main__\":\n",
    "    build_full_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdf8d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9430b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f190d633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adecf011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffab450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08436b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46d898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e78ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d760b6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dede79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1aa607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aabcc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335f7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff32c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ad86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc9ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb86b122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73af4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
